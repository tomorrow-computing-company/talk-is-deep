# talk-is-deep

This repository contains the code and resources for the "Talk is Deep" project, which aims to generate 1 million scientific conversations and train large language models on them. The project pipeline includes:

1. Conversation Generation: Scripts and prompts for generating diverse, engaging scientific conversations between a student and professor persona. The conversations cover a wide range of scientific topics and aim to simulate natural, in-depth discussions.

2. Data Processing: Code for cleaning, formatting, and preparing the generated conversations for training language models. This includes tokenization, encoding, and creating training/validation datasets.

3. Model Training: Scripts and configurations for fine-tuning large language models (Llama3, Mistral, Gemma, Phi supported here) on the generated conversation data. The goal is to create models that can engage in knowledgeable, context-aware scientific discussions, and also to improve the conversational abilities of smaller models.

4. Evaluation & Testing: Metrics and tools for evaluating the performance of the trained models, including perplexity, coherence, factual accuracy, and human evaluations. Sample conversations and prompts are provided for testing the models' capabilities.

5. Deployment: Instructions and code for deploying the trained models in a conversational AI application, allowing users to engage in scientific discussions with the AI assistant.

The repository is organized into directories for each stage of the pipeline, with detailed READMEs explaining usage and dependencies. We welcome contributions, suggestions, and collaborations to further improve the generation and modeling process.

Let's make scientific knowledge more accessible and engaging through the power of conversational AI!
